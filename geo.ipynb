{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b4b2612-da2f-45f7-9fa6-d8088126d965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import json\n",
    "import requests\n",
    "import networkx as nx\n",
    "import urllib.parse\n",
    "from datetime import date\n",
    "from math import radians, sin, cos, atan2, sqrt, isnan\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd31328-ed3f-4efb-9cc3-3330963c4982",
   "metadata": {},
   "source": [
    "Read in CSV data, clean it up, and prepare the first section of the json data that will be exported.\n",
    "This first section is the csv converted to json format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa3b6b2c-9244-4900-afee-5bd9649c6277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('1854 WCR 2023.csv',header=1).drop(columns=['Column1','Direction'])\n",
    "df['Where Bound'] = df['Where Bound'].apply(lambda x: str(x).strip())\n",
    "df['Where From'] = df['Where From'].apply(lambda x: str(x).strip())\n",
    "\n",
    "#exclude rows where locations have not be filled in or lon/lat could not be determined\n",
    "exclude_list = ['?','','nan','Bear Creek','bear Creek','Miloin','Port Price']\n",
    "\n",
    "df = df[(~df['Where Bound'].isin(exclude_list)) & (~df['Where From'].isin(exclude_list))]\n",
    "\n",
    "def not_empty(item):\n",
    "    if type(item) == float and isnan(item):\n",
    "        return False\n",
    "    elif type(item) == type(None):\n",
    "        return False \n",
    "    elif type(item) == str and item.strip() == '':\n",
    "        return False\n",
    "    else: \n",
    "        return True\n",
    "\n",
    "cargo = []\n",
    "for i,v in df[['Cargo 1', 'Cargo 2', 'Cargo 3', 'Cargo 4']].iterrows():\n",
    "    cargo_this = map(str.strip, filter(not_empty, [v['Cargo 1'], v['Cargo 2'], v['Cargo 3'],v['Cargo 4']]))\n",
    "    cargo.append(list(cargo_this))\n",
    "df['Cargo'] = cargo\n",
    "df = df.drop(columns=['Cargo 1', 'Cargo 2', 'Cargo 3', 'Cargo 4'])\n",
    "\n",
    "#Check values are clean\n",
    "assert (df['Year'].apply(lambda x: x == 1854.0).all())\n",
    "assert df['Day'].apply(lambda x: x>=1 and x<=31).all()\n",
    "\n",
    "for col in ['Nationality', 'Vessel Type', 'Name of Vessel']:\n",
    "    df[col] = df[col].apply(str.strip)\n",
    "\n",
    "month_to_int = {\"January\":1, \"Febuary\":2, \"March\": 3, \"April\": 4, \"May\": 5, \n",
    " \"June\":6, \"July\":7, \"August\":8, \"September\":9,\"October\":10,\"November\":11, \"December\":12}\n",
    "df['Date'] = df[['Year','Month','Day']].apply(lambda x: str(date(int(x.Year), month_to_int[x.Month], int(x.Day))), axis=1)    \n",
    "df.drop(columns=['Year','Month','Day'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c2820-5182-490a-a989-78a2f0d3413e",
   "metadata": {},
   "source": [
    "Show some information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d40c91-fe4f-4f5a-bb47-645f907ad424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'British', 'American'}\n",
      "{'Propeller', 'Brigantine', 'Sail Boat', 'Schooner', 'Barkentine', 'Brigantineantine', 'Steamer'}\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "print(set(df['Nationality']))\n",
    "print(set(df['Vessel Type']))\n",
    "\n",
    "#Total number of days\n",
    "print(len(df[['Month','Day']].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ed3dc-ad4e-46f2-857c-7290aecf3488",
   "metadata": {},
   "source": [
    "Read in the shipping path data that was converted to json using ArcGis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6884aa87-0a82-4f52-81a1-ca1286f2e0f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('water_paths.json') as wp_geojson:\n",
    "    gj = json.loads(wp_geojson.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a0aed0-256d-464a-a5dc-1afd5b0b7918",
   "metadata": {},
   "source": [
    "Define functions for transforming the path information into a graph and working with that graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122df4cb-bb69-4a45-9939-e7caf441178f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_filter(gj, gid_list=None, exclude=True):\n",
    "    '''filter out features from geojson. optionally exclude or include only features with gid in gid_list.'''\n",
    "    filtered = []\n",
    "    for f in gj['features']:\n",
    "        if not gid_list:\n",
    "            filtered.append(f)\n",
    "            continue\n",
    "            \n",
    "        if exclude and f['properties']['gid'] not in gid_list: \n",
    "            filtered.append(f)\n",
    "        elif not exclude and f['properties']['gid'] in gid_list: \n",
    "            filtered.append(f)\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "def distance(p1, p2):\n",
    "    '''returns distance in KM between two points'''\n",
    "    earth_radius = 6371\n",
    "    lat1, lat2 = radians(p1[1]), radians(p2[1])\n",
    "    lon1, lon2 = radians(p1[0]), radians(p2[0])\n",
    "    \n",
    "    #https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    base = earth_radius * c\n",
    "    return base\n",
    "\n",
    "def draw_graph(G):\n",
    "    pos = nx.planar_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, font_weight='bold')\n",
    "    el=nx.get_edge_attributes(G,'weight')\n",
    "    nx.draw_networkx_edge_labels(G,pos,edge_labels=el)\n",
    "\n",
    "def path_distance(g, path):\n",
    "    prev = path[0]\n",
    "    distances = []\n",
    "    for p in path[1:-1]:\n",
    "        distances.append(g.edges[(prev,p)]['weight'])\n",
    "        prev = p\n",
    "    p = path[-1]\n",
    "    distances.append(g.edges[(prev,p)]['weight'])\n",
    "    return sum(distances)\n",
    "\n",
    "def geojson_to_graph(features):\n",
    "    G = nx.Graph()\n",
    "    for feat in features:\n",
    "        feat_geo = feat['geometry']['coordinates']\n",
    "        anode = str(feat['properties']['anode'])\n",
    "        bnode = str(feat['properties']['bnode'])\n",
    "        #length = feat['properties']['length']\n",
    "        id = feat['properties']['OBJECTID']\n",
    "        id_postfix = 1\n",
    "        G.add_node(anode, coordinates=tuple(feat_geo[0]))\n",
    "        G.add_node(bnode, coordinates=tuple(feat_geo[-1]))\n",
    "\n",
    "        prev = anode\n",
    "        prev_coord = feat_geo[0]\n",
    "        for point in feat_geo[1:-1]:\n",
    "            name = f\"{id}_{id_postfix}\"\n",
    "            id_postfix += 1\n",
    "            G.add_node(name, coordinates=tuple(point))\n",
    "            G.add_edge(prev,name, weight=distance(prev_coord, point))\n",
    "            prev = name\n",
    "            prev_coord = point\n",
    "        G.add_edge(prev, bnode, weight=distance(prev_coord, feat_geo[-1]))\n",
    "    return G\n",
    "\n",
    "def coordinates_set(g):\n",
    "    return {g.nodes[node]['coordinates'] for node in g.nodes}\n",
    "\n",
    "def closest_coordinate(all_cords, candidate_points):\n",
    "    point_distances = []\n",
    "    for point in candidate_points:\n",
    "        #find the closest node coordinate in the path graph to this point\n",
    "        cc = sorted(all_cords, key=lambda coord: distance(coord, point))[0]\n",
    "        #note down the point and the distance to its closest coordinate\n",
    "        point_distances.append((cc, point, distance(cc, point)))\n",
    "    \n",
    "    #return the pair that has the smallest distance\n",
    "    return sorted(point_distances, key=lambda record: record[2])[0]\n",
    "\n",
    "def get_features_coords(features):\n",
    "    return [feat['center'] for feat in features]\n",
    "\n",
    "def location_name_to_coord(g, locations):\n",
    "    '''Using the geocoding api, map locations to their most likely lat/lon'''\n",
    "    req_url = 'https://api.mapbox.com/geocoding/v5/mapbox.places/{}.json?proximity=ip&access_token=pk.eyJ1IjoiZmpvaG5zODg4IiwiYSI6ImNsaGh6dnh2ajAzNDkzcXM1OWxwOWF1amIifQ._g2Uwo_6wLTw12W5R-b57w'\n",
    "    mapping = {}\n",
    "    all_coords = coordinates_set(g)\n",
    "    \n",
    "    for loc in locations:\n",
    "        features = requests.get(req_url.format(urllib.parse.quote(loc))).json()\n",
    "        assert len(features['features']), features\n",
    "        \n",
    "        #Use this instead to compare all returned search resutls against graph coordinates\n",
    "        #use the pair that has the minimum distance from one another\n",
    "        #candidate_points = get_features_coords(features['features'])\n",
    "        #cc = closest_coordinate(all_coords, candidate_points)\n",
    "        #mapping[loc] = {'graphcoord':cc[0], 'geocoded_coord':cc[1]}\n",
    "        \n",
    "        geocode = features['features'][0] #get the first and most relevant result\n",
    "        cc = closest_coordinate(all_coords, [geocode['center']])\n",
    "        mapping[loc] = {'graphcoord':cc[0], 'geocoded_coord':cc[1], 'geocode_name': geocode['place_name']}\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "def coord_to_node(coordinate):\n",
    "    for node in g.nodes:\n",
    "        if g.nodes[node]['coordinates'] == coordinate:\n",
    "            return node\n",
    "    raise ValueError(\"Could not find node matching given coordinate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbac965-9f1f-49fa-8966-447e6b634c59",
   "metadata": {},
   "source": [
    "Create the graph representation of the geojson data. Create mappings using the Mapbox geocoding api that translate place names to lon/lat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62dddb62-7b80-4c8f-98a6-649598a48555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "location_strings = set(df['Where Bound'])\n",
    "location_strings.update(df['Where From'])\n",
    "location_strings = sorted(location_strings)\n",
    "\n",
    "#Exclude the lone multiline path in the geojson data\n",
    "#this is okay since it its a series of disconnectd strings anyways\n",
    "features = feature_filter(gj, [837], exclude=True)\n",
    "g = geojson_to_graph(features)\n",
    "loc_cord_map = location_name_to_coord(g, location_strings)\n",
    "loc_node_map = {loc:coord_to_node(loc_cord_map[loc]['graphcoord']) for loc in location_strings}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b25517-24e0-4c16-889e-401366856e3f",
   "metadata": {},
   "source": [
    "Some functions that output feature collections (geojson) of the locations that were previously just strings. Basically just used to verify locations that were looked up using the geocoding api make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bfcd74-bd5b-4711-ac25-b144b0cba978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mapping_to_geojson(mapping):\n",
    "    '''Dump location lon/dat data'''\n",
    "    \n",
    "    features = {\n",
    "      \"type\": \"FeatureCollection\",\n",
    "      \"features\": []\n",
    "    }\n",
    "    for loc in mapping:\n",
    "        loc_gj = {\"type\": \"Feature\",\n",
    "                  \"id\": loc,\n",
    "                  \"geometry\": {\n",
    "                      \"type\": \"Point\", \n",
    "                      \"coordinates\": mapping[loc]['graphcoord']},\n",
    "                  \"properties\": {\"name\": loc}}\n",
    "        features['features'].append(loc_gj)\n",
    "    return json.dumps(features)\n",
    "\n",
    "def mapping_to_geojson_debug(mapping):\n",
    "    '''Dump queried/looked up lon/lat locations with their most likely graph locations.\n",
    "    Provided as a LineString so that the discrepancy can be observed'''\n",
    "    \n",
    "    linefeatures = {\n",
    "      \"type\": \"FeatureCollection\",\n",
    "      \"features\": []\n",
    "    }\n",
    "    estfeatures = {\n",
    "      \"type\": \"FeatureCollection\",\n",
    "      \"features\": []\n",
    "    }\n",
    "    realfeatures = {\n",
    "      \"type\": \"FeatureCollection\",\n",
    "      \"features\": []\n",
    "    }\n",
    "    features = {}\n",
    "    \n",
    "    for loc in mapping:\n",
    "        loc_gj = {\"type\": \"Feature\",\n",
    "                  \"id\": loc,\n",
    "                  \"geometry\": {\n",
    "                      \"type\": \"LineString\", \n",
    "                      \"coordinates\": [mapping[loc]['graphcoord'], mapping[loc]['geocoded_coord']]},\n",
    "                  \"properties\": {\"name\": loc}}\n",
    "        est = {\"type\": \"Feature\",\n",
    "               \"id\": loc,\n",
    "               \"geometry\":{\"type\":\"Point\", \"coordinates\":mapping[loc]['graphcoord']},\n",
    "               \"properties\":{\"name\":loc}}\n",
    "        real = {\"type\": \"Feature\",\n",
    "               \"id\": loc,\n",
    "               \"geometry\":{\"type\":\"Point\", \"coordinates\":mapping[loc]['geocoded_coord']},\n",
    "               \"properties\":{\"name\":mapping[loc]['geocode_name']}}\n",
    "        linefeatures['features'].append(loc_gj) \n",
    "        estfeatures['features'].append(est)\n",
    "        realfeatures['features'].append(real)\n",
    "    \n",
    "    features['lines'] = linefeatures\n",
    "    features['estimation'] = estfeatures\n",
    "    features['real'] = realfeatures\n",
    "    return json.dumps(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ee9ab1-4d3e-4cfa-9675-dc816db84f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "debug = mapping_to_geojson_debug(loc_cord_map)\n",
    "with open('debug.json','w') as debug_file:\n",
    "    debug_file.write(debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5cc5e-9189-460d-9722-f07a3159bef2",
   "metadata": {},
   "source": [
    "Code for navigating the created graph representation and deriving the shortest paths for the 'Where From' and 'Where Bound' columns of the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b60afb5-79cd-4cc0-80d0-6c9d952a7b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def path_to_coordinates(g, path):\n",
    "    return [g.nodes[node]['coordinates'] for node in path]\n",
    "\n",
    "def coordinates_to_geojson(coordinates):\n",
    "    geo_json = {\"type\": \"Feature\",\n",
    "                \"properties\":{},\n",
    "                \"geometry\":{\n",
    "                    \"type\":\"LineString\",\n",
    "                    \"coordinates\":[]\n",
    "                }}\n",
    "                \n",
    "    \n",
    "    for coordinate in coordinates:\n",
    "        geo_json['geometry']['coordinates'].append(list(coordinate))\n",
    "    \n",
    "    return geo_json\n",
    "\n",
    "def shortest_path_to_geojson(g, start, end):\n",
    "    if isinstance(start, int): \n",
    "        start = str(start)\n",
    "    if isinstance(end, int):\n",
    "        end = str(end)\n",
    "        \n",
    "    sp = nx.shortest_path(g,start,end, weight='weight')\n",
    "    return coordinates_to_geojson(path_to_coordinates(g, sp))\n",
    "\n",
    "def shortest_paths_to_geojson(g, start_end_pairs):\n",
    "    '''Given a list of star/end pairs, find the shortest path and return it as a series of linestrings in geojson'''\n",
    "    geo_json = {\"type\":\"FeatureCollection\",\n",
    "                \"features\":[]\n",
    "               }\n",
    "    geo_json['features'] = [shortest_path_to_geojson(g, start, end) for start, end in start_end_pairs]\n",
    "    return geo_json\n",
    "\n",
    "def gen_all_paths(g, df, loc_node_map):\n",
    "    paths = []\n",
    "    bad_paths = set()\n",
    "    for _,locs in df[['Where From','Where Bound']].drop_duplicates().iterrows():\n",
    "        start_name = locs['Where From']\n",
    "        dst_name = locs['Where Bound']\n",
    "        node_start = loc_node_map[start_name]\n",
    "        node_end = loc_node_map[dst_name]\n",
    "        path_name = f\"{start_name}+{dst_name}\"\n",
    "        try:\n",
    "            feature = shortest_path_to_geojson(g, node_start, node_end)\n",
    "            feature['properties']['path'] = path_name\n",
    "            paths.append(feature)\n",
    "        except nx.NetworkXNoPath:\n",
    "            bad_paths.add(path_name)\n",
    "    \n",
    "    feature_collection = {\"type\":\"FeatureCollection\", \"features\":paths}\n",
    "    return json.dumps(feature_collection), bad_paths\n",
    "good,bad = gen_all_paths(g, df, loc_node_map)\n",
    "assert not bad, bad\n",
    "    \n",
    "# Save cleaned dataframe as JSON    \n",
    "manifest = df.to_json(orient=\"records\")\n",
    "\n",
    "with open('manifest.json','w') as manifest_file:\n",
    "    manifest_file.write(f'{{\"manifest\":{manifest},\\n \"routes\":{good}}}')\n",
    "    \n",
    "#loc_node_map        \n",
    "# with open('path.json', 'w') as pf:\n",
    "#     pf.write(shortest_paths_to_geojson(g, [(63100, 300830), (5050, 65450), (490,62870), (62570,300730), (67050, 64470)]))\n",
    "#shortest_path_to_geojson(g, 63100, 300830)\n",
    "#g.nodes['64470']['coordinates']\n",
    "#path_distance(g,sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d4532-e9ac-4c6d-9e7a-39ca825fc3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad = {'Bear Creek+Clayton', 'Kingston+Bear Creek', 'bear Creek+Kingston', 'Port Hope+Bear Creek', 'Toronto+Bear Creek', 'Port Dalhousie+Bear Creek', 'Hamilton+Bear Creek', 'Oakville+Bear Creek', 'Oswego+Miloin', 'Clayton+Bear Creek', 'Bear Creek+Kingston', 'Port Metcalf+Bear Creek', 'Bear Creek+Ogdensburg', 'Kingston+bear Creek', 'St. Catharines+Bear Creek', 'Kingston+Port Price'}\n",
    "newbad = set()\n",
    "for item in bad:\n",
    "    newbad.update(item.split('+'))\n",
    "newbad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6083f685-ecd0-4a0b-91f9-d8b8345eed38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910b35f-7f8d-4a79-a5fe-70a35d0f90c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g.edges[('226020', '7_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6e50b-7174-4869-a8fa-9ac098361e66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g.nodes['82_1'],g['82_1'],g.nodes['11300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042ea2d-efa3-4603-8e5c-6361c5b265ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (u, v, wt) in g.edges.data('weight'):\n",
    "    print(u,v,wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ed993-a868-4998-8a72-7048e1f5970e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum([tup[2] for tup in g.edges.data('weight')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c0d57e-f1c7-43c0-b8db-6a5293c60bec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp = nx.shortest_path(g,'63100','62290', weight='weight')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53756f05-d768-4b66-9512-9d0427671fa1",
   "metadata": {},
   "source": [
    "shortest_path_to_geojson(g, 490, 62870)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7be4dcb0-e00e-47cd-873e-885b96f853ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1854-04-04\n",
       "1       1854-04-04\n",
       "2       1854-04-05\n",
       "3       1854-04-05\n",
       "4       1854-04-06\n",
       "           ...    \n",
       "1944    1854-11-24\n",
       "1945    1854-11-24\n",
       "1946    1854-11-25\n",
       "1947    1854-11-27\n",
       "1948    1854-12-01\n",
       "Name: Date, Length: 1852, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c70088c3-a434-46d4-90c2-4aceaabe2b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "manifest = df.to_json(orient=\"records\")\n",
    "\n",
    "with open('manifest.json','w') as manifest_file:\n",
    "    manifest_file.write(f'{{\"manifest\":{manifest},\\n \"routes\":{good}}}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
